version: "3"
services:

  # Database instance.
  db:
    image: "postgres:12.8"
    environment:
      POSTGRES_HOST_AUTH_METHOD: "trust"
    volumes:
      - tamato-data-volume:/var/lib/postgresql/data
    ports:
      - "127.0.0.1:5431:5432"
    restart: "${DOCKER_RESTART_POLICY:-unless-stopped}"
    shm_size: 32g
    stdin_open: true
    tty: true
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 5s
      retries: 5

  # Redis instance used as a Django cache store.
  cache-redis:
    image: redis
    ports:
      - "127.0.0.1:6379:6379"
    restart: "${DOCKER_RESTART_POLICY:-unless-stopped}"

  # Redis instance used as Celery's broker instance.
  celery-redis:
    image: redis
    ports:
      - "127.0.0.1:6378:6379"
    restart: "${DOCKER_RESTART_POLICY:-unless-stopped}"

  # General purpose Celery worker - notifications, publishing and sqlite snapshots.
  celery:
    build:
      context: .
      args:
        - "ENV=${ENV:-prod}"
    volumes:
      - ./:/app/
    command: sh -c "celery -A common.celery worker -O fair -l info -Q standard"
    env_file:
      - .env
      - settings/envs/docker.env
    restart: "${DOCKER_RESTART_POLICY:-unless-stopped}"
    stdin_open: true
    tty: true
    depends_on:
      - celery-redis

  # Celery worker used to execute business rule checks on workbaskets.
  rule-check-celery:
    build:
      context: .
      args:
        - "ENV=${ENV:-prod}"
    volumes:
      - ./:/app/
    command: sh -c "celery -A common.celery worker -O fair -l info -Q rule-check --concurrency 1"
    env_file:
      - .env
      - settings/envs/docker.env
    restart: "${DOCKER_RESTART_POLICY:-unless-stopped}"
    stdin_open: true
    tty: true
    depends_on:
      - celery-redis

  # Celery worker for bulk creating and editing of objects.
  bulk-create-celery:
    build:
      context: .
      args:
        - "ENV=${ENV:-prod}"
    volumes:
      - ./:/app/
    command: sh -c "celery -A common.celery worker -O fair -l info -Q bulk-create --concurrency 1"
    env_file:
      - .env
      - settings/envs/docker.env
    restart: "${DOCKER_RESTART_POLICY:-unless-stopped}"
    stdin_open: true
    tty: true
    depends_on:
      - celery-redis

  # Celery worker used to execute importer parser and objection creation.
  importer-celery:
    build:
      context: .
      args:
        - "ENV=${ENV:-prod}"
    volumes:
      - ./:/app/
    command: sh -c "celery -A common.celery worker -O fair -l info -Q importer --concurrency 1"
    env_file:
      - .env
      - settings/envs/docker.env
    restart: "${DOCKER_RESTART_POLICY:-unless-stopped}"
    depends_on:
      - celery-redis

  # Celery Beat process, used to execute scheduled, cron-like tasks.
  celery-beat:
    build:
      context: .
      args:
        - "ENV=${ENV:-prod}"
    volumes:
      - ./:/app/
    command: sh -c "celery -A common.celery beat -l info"
    env_file:
      - .env
      - settings/envs/docker.env
    restart: "${DOCKER_RESTART_POLICY:-unless-stopped}"
    stdin_open: true
    tty: true
    depends_on:
      - celery-redis

  # Minio object store instance providing S3-like APIs and capabilities.
  s3:
    image: minio/minio
    ports:
      - "127.0.0.1:9000:9000"
      - "127.0.0.1:9001:9001"
    volumes:
      - tamato-s3-volume:/data
    env_file: .env
    entrypoint: sh
    restart: "${DOCKER_RESTART_POLICY:-unless-stopped}"
    command: -c "mkdir -p /data/importer && mkdir -p /data/hmrc-packaging && minio server --quiet /data --console-address ':9001'"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

  # Web application process.
  tamato:
    build:
      context: .
      args:
        - "ENV=${ENV:-prod}"
    image: tamato
    volumes:
      - "${DOCKER_WEB_VOLUME:-./:/app/}"
    ports:
      - "127.0.0.1:8000:8000"
    depends_on:
      - db
      - cache-redis
      - celery-redis
      - celery
      - rule-check-celery
      - importer-celery
      #- celery-beat # Normally only required in production environments.
      - s3
    env_file:
      - .env
      - settings/envs/docker.env
    command: sh -c "python manage.py runserver 0.0.0.0:8000"
    restart: "${DOCKER_RESTART_POLICY:-unless-stopped}"
    stdin_open: true
    tty: true

  pytest-db:
    # With no persistent volume, it's possible to clear the database contents by
    # simply stopping this service: docker-compose stop pytest-db.
    image: "postgres:16"
    environment:
      POSTGRES_HOST_AUTH_METHOD: "trust"
      POSTGRES_USER: postgres
      POSTGRES_DB: tamato
    ports:
      # Map a port from the host to allow inspection via DB clients, e.g.:
      # $ psql --host=127.0.0.1 --port=5430 --username=postgres --dbname=tamato
      - "127.0.0.1:5430:5432"

  pytest:
    build:
      context: .
      dockerfile: Dockerfile.pytest
    image: pytest
    depends_on:
      - pytest-db
    environment:
      DATABASE_URL: postgres://postgres@pytest-db/tamato
      DJANGO_SETTINGS_MODULE: settings.test
      ENV: test
    command: sh -c "python manage.py migrate && pytest"
    stdin_open: true
    tty: true

  cypress:
    image: cypress/base:latest

volumes:
  tamato-data-volume: {}
  tamato-s3-volume: {}
